---
title: "The importance of reproducibility in COVID-19 research: the case of population density and the spread of the pandemic"
author:
  - name: Antonio Paez
    email: paezha@mcmaster.ca
    affiliation: McMaster University
    corresponding: paezha@mcmaster.ca
address:
  - code: McMaster University
    address: School of Earth, Environment and Society, 1280 Main St West, Hamilton, Ontario L8S 4K1 Canada
abstract: |
  The emergence of the novel SARS-CoV-2 coronavirus and the global COVID-19 pandemic has led to explosive growth in scientific research. Given the high stakes of the situation, it is essential that scientific activites, on which good policy depends, are as transparent and reproducible as possible. Reproducibility is key for the efficient operation of the self-correction mechanisms of science, which work to weed out errors and refine our understanding of social and physical phenomena. In this paper, the importance of reproducibility is illustrated for the case of the association between population density and the the spread of SARS-CoV-2. Transparency and openness means that the same problem can, with relatively modest efforts, be examined by independent researchers who can verify findings, and bring to bear different perspectives, approaches, and methods—sometimes with consequantial changes in the conclusions, as the empirical example in this paper shows.
  
author_summary: |

bibliography: bibliography.bib
output: rticles::plos_article
csl: plos.csl
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = TRUE)
```

```{r install-data-package, include = FALSE}
# Run only once if needed to install data package `sobiEquity`
if (!require("r0density", character.only = TRUE)) {
      devtools::install_github("https://github.com/paezha/Reproductive-Rate-and-Density-US-Reanalyzed", subdir = "r0density")
  }
```

```{r load-packages, include=FALSE, cache=FALSE}
library(censReg)
library(Matrix)
library(nlme)
library(r0density) # Data package
library(spatialprobit)
library(spdep)
library(tidycensus)
library(tidyverse)
library(units)
```

```{r invoke-data, include=FALSE}
data(county_geo)
```

```{r prepare-data, include=FALSE}
# Convert missing R's to zeros and calculate expansion variables: 
county_geo_clean <- county_geo %>%
  mutate(R = replace_na(R, 0),
         density_log = log(drop_units(density)),
         density_2 = drop_units(density)^2,
         hincome_log = log(hincome),
         private = car/commuters * 100) %>% # Percentage of commuters who travel by car/van/truck) %>%
  drop_na(commuters) %>%
  st_as_sf()
```

```{r list-of-geographical-neighbors, include=FALSE}
# Create a list of neighbors based on the polygons; the default contiguity criterion is Queen:
county_nb <- poly2nb(county_geo_clean)
```

```{r spatial-data-check, include=FALSE}
# Check list of neighbors
summary(county_nb)

# Notice that there are 9 counties that are isolates. These are the counties that do not have neighbors based on contiguity
county_geo_clean[c(69, 546, 547, 549, 1226, 1876, 2974, 3146, 3200),]

# To rectify the lack of neighbors, find the first nearest neighbor using the centroids:
county_nb_dist <- knearneigh(county_geo_clean %>% 
                               st_centroid()) %>%
  knn2nb()

# Add nearest neighbor to isolates:
county_nb[[69]] <- county_nb_dist[[69]]
county_nb[[546]] <- county_nb_dist[[546]]
county_nb[[547]] <- county_nb_dist[[547]]
county_nb[[549]] <- county_nb_dist[[549]]
county_nb[[1226]] <- county_nb_dist[[1226]]
county_nb[[1876]] <- county_nb_dist[[1876]]
county_nb[[2974]] <- county_nb_dist[[2974]]
county_nb[[3146]] <- county_nb_dist[[3146]]
county_nb[[3200]] <- county_nb_dist[[3200]]
```

```{r spatial-weights, include=FALSE}
# Convert the nearest neighbor object to a listw object:
nb_B <- nb2listw(county_nb, 
                 style="B", 
                 zero.policy = TRUE)

# Convert listw to sparse matrix for use in spatial tobit:
B <- as(nb_B, "CsparseMatrix")
```

# Introduction

The emergence of the novel SARS-CoV-2 coronavirus in 2019, and the global pandemic that followed in its wake, led to an explosive growth of research. According to Fraser et al. [-@Fraser2021evolving], over 125,000 COVID-19-related papers were released in the first ten months from the first confirmed case of the disease. Of these, more than 30,000 were shared in pre-print servers, the use of which also exploded in the past year [@Kwon2021swamped; @Vlasschaert2020proliferation; @Anazco2021publication]. 

Given the heavy human and economic cost of the pandemic, there has been a natural tension in the scientific community between the need to publish research results quickly and the imperative to maintain consistently high quality standards in scientific reporting; indeed, a call for maintaining the standards in published research has even called this deluge of publications a "carnage of substandard research" [@Bramstedt2020carnage]. Part of the challenge of maintaining quality standards in published research is that, despite an abundance of recommendations and guidelines [@Broggini2017reproducible; @Ince2012case; @Ioannidis2014increasing; @Brunsdon2020opening], in practice reproducibility has remained a lofty but somewhat aspirational goal [@Konkol2019examination; @Konkol2019computational]. As reported in the literature, only a woefully small proportion of published research was actually reproducible before the pandemic [@Iqbal2016reproducible; @Stodden2018empirical], a situation that does not appear to have changed substantially since [@Sumner2020reproducibility; @Gustot2020quality].

The push for open data and software, along with more strenuous efforts towards open, reproducible research, is simply a continuation of long-standing scientific practices of independent verification. Despite the (at times disproportionate) attention that high profile scandals in science tend to elicit in the media, science as a collective endeavor is remarkable for being a self-correcting enterprise, one with built-in mechanisms and incentives to weed out erroneous ideas. Over the long term, facts tend to prevail in science. At stake is the shorter-term impacts that research may have in other spheres of economic and social life. The case of economists Reinhart and Rogoff comes to mind: by the time the inaccuracies in their research were uncovered [see @Herndon2014high], their claims about debt and economic growth had already been seized by policy-makers on both sides of the Atlantic to justify austerity policies in the aftermath of the Great Recession of 2007-2009^[Nobel Prize in Economics Paul Krugman noted that "Reinhart–Rogoff may have had more immediate influence on public debate than any previous paper in the history of economics" \url{https://www.nybooks.com/articles/2013/06/06/how-case-austerity-has-crumbled/?pagination=false}]. As later research has demonstrated, those policies cast a long shadow, and their sequels continued to be felt for years [@Basu2017ten]. 

In the context of COVID-19, a topic that has grabbed the imagination of numerous thinkers has been the prospect of life in cities after the pandemic [@Florida2020how]. The fact that the worst of the pandemic was initially felt in dense population centers such as Wuhan, Milan, Madrid, and New York, prompted a flurry of research into the associations between density and the spread of the pandemic. Some important questions hang on the results of these research efforts. For example, are lower density regions safer from the pandemic? Are de-densification policies warranted, at least in the short term? And in the longer term, will the risks of life in high density regions presage a flight from cities? Over the past year, numerous papers have sought to throw light into the underlying issue of density and the pandemic; nonetheless the results, as will be detailed next, remain mixed. Further, to complicate matters, precious few of these studies appear to be sufficiently open to support independent verification.

The objective of this paper is to illustrate the importance of reproducibility in research, particularly in the context of the flood of COVID-19 papers. To this end, a recent study by Sy et al. [@Sy2021population] is chosen as an example of reproducible research. The objective is not to malign the analysis of these researchers, but rather to demonstrate the value of openness to allow for independent verification and further analysis. Open data and open code mean that an independent researcher can, with only modest efforts, not only verify the findings reported, but also examine the same data from a perspective which may not have been available to the original researchers due to differences in disciplinary perspectives, methodological traditions, and/or training, among other possible factors. The example, which shows consequential changes in the conclusions reached by different analyses, should serve as a call to researchers to redouble their efforts to increase transparency and reproducibility in research. This paper, in addition, aims to show how data can be packaged in well-documented, shareable units, and code can be embedded into self-contained documents suitable for review and independent verification. The source for this paper is an [R Markdown](http://rmarkdown.rstudio.com) document which, along with the data package, is available in a public repository^[\url{https://github.com/paezha/Reproductive-Rate-and-Density-US-Reanalyzed}].

# Background

The concern with population density and the spread of the virus during the COVID-19 pandemic was fueled, at least in part, by dramatic scenes seen in real-time around the world from large urban centers such as Wuhan, Milan, Madrid, and New York. In theory, there are good reasons to believe that higher density may have a positive association with the transmission of a contagious virus. It has long been known that the potential for inter-personal contact is greater in regions with higher density [see for example the research on urban fields and time-geography @Moore1970urban; @Moore1970some; @Farber2011running]. Mathematically, models of exposure and contagion indicate that higher densities can catalyze the transmission of contagious diseases [@Rocklov2020high; @Li2018effect]. Models such as these were likely at the root of messages, by some figures in positions of authority, that low density regions faced lower risks from the pandemic^[Governor Kristi Noem of South Dakota, for example, claimed that sparse population density allowed her state to face the pandemic without the need for strict policy interventions \url{https://www.inforum.com/lifestyle/health/5025620-South-Dakota-is-not-New-York-City-Noem-defends-lack-of-statewide-COVID-19-restrictions}]. 

As Rocklöv and Sjödin [@Rocklov2020high] note, however, mathematical models of contagion are valid at small-to-medium spatial scales (and presumably, small temporal scales too, such as time spent in restaurants, concert halls, cruises), and the results do not necessarily transfer to larger spatial units and different time scales. There are good reasons for this: while in a restaurant, one can hardly avoid being in proximity to other customers-however, a person can choose to (or be forced to as a matter of policy) not go to a restaurant in the first place. Nonetheless, the idea that high density correlates with high transmission is so intuitive that it is often taken for granted even at larger scales [e.g., @Cruz2020exploring; @Micallef2020first]. At larger scales, however, there exists the possibility of behavioral adaptations, which are difficult to capture in the mechanistic framework of differential equations [or can be missing in agent-based models, @Gomez2021infekta]; these adaptations, in fact, can be a key aspect of disease transmission. 

A plausible behavioral adaptiation during a pandemic, especially one broadcast as widely and intensely as COVID-19, is risk compensation. Risk compensation is a process whereby people adjust their behavior in response to their _perception_ of risk [@Noland1995perceived; @Richens2000condoms; @Phillips2011risk]. For example, it is possible that people who listened to the message of leaders saying that they were safe because of low density may not have taken adequate precautions. People in dense places who could more directly observe the impact of the pandemic may have become overly cautious. Both Paez et al. [-@Paez2020spatio] and Hamidi et al. [-@Hamidi2020density] posit this mechanism (i.e., greater compliance with social distancing in denser regions) to explain the results of their analyses. The evidence available does indeed show that there were important changes in behavior during the pandemic, at least with respect to mobility [@Jamal2020Changes; @Harris2021Changes; @Molloy2020Tracing]; furthermore, shelter in place orders may have had greater buy-in from the public in higher density regions [@Feyman2020effectiveness], and the behavior may have persisted beyond the duration of official social-distancing policies [@Praharaj2020Using]. In addition, there is evidence that changes in mobility correlated with the trajectory of the pandemic [@Paez2020using; @Noland2021mobility]. Given the potential for behavioral adaptation, the question of density becomes more nuanced: it is not just a matter of proximity, but also of human behavior, which is better studied using population-level data and models.

In this respect, the literature to date remains inconclusive. 

On the one hand, there are studies that report positive associations between population density and various COVID-19-related outcomes. Bhadra [-@Bhadra2021impact], for example, reported a moderate positive correlation between the spread of COVID-19 and population density at the district level in India, however their analysis was bivariate and did not control for other variables, such as income. Similarly, Kadi and Khelfaoui [-@Kadi2020population] found a positive and significant correlation between number of cases and population density in cities in Algeria in a series of simple regression models (i.e., without other controls). A question in these relatively simple analyses is whether density is not a proxy for other factors. Other studies have included controls, such as Pequeno et al. [-@Pequeno2020air], a team that reported a positive association between density and cumulative counts of confirmed COVID-19 cases in state capitals in Brazil after controlling for covariates, including income, transport connectivity, and economic status. In a similar vein, Fielding-Miller et al. [-@Fielding2020social] reported a positive relationship between the absolute number of COVID-19 deaths and population density (rate) in rural counties in the US. Roy and Ghosh [-@Roy2020factors] used a battery of machine learning techniques to find discriminatory factors, and a positive and significant association between COVID-19 infection and death rates in US states. Wong and Li [-@Wong2020spreading] also found a positive and significant association between population density and number of confirmed COVID-19 cases in US counties, using both univariate and multivariate regressions with spatial effects. Most recently, Sy et al. [-@Sy2021population] reported that the basic reproductive number of COVID-19 in US counties tends to increase with population density, but at a decreasing rate at higher densities.

On the gripping hand, a number of studies report non-significant or negative associations between population density and COVID-19 outcomes. This includes the research of Sun et al. [-@Sun2020impacts] who did not find evidence of significant correlation between population density and confirmed number of cases per day _in conditions of lockdown_ in China. This finding echoes the results of Paez et al. [-@Paez2020spatio], who in their study of provinces in Spain reported non-significant associations between population density and infection rates in the early days of the first wave of COVID-19, and negative significant associations in the later part of the first lockdown. Similarly, [-@Skorka2020macroecology] found zero or negative associations between population density and infection numbers/deaths by country. Fielding-Miller et al. [-@Fielding2020social] found a negative relationship between COVID-19 deaths and population density urban counties in the US. In their investigation of doubling time, White and Hébert-Dufresne [-@White2020state] identified a negative and significant correlation between population density and doubling time in US states. Likewise, [-@Khavarian2021high] fond a small negative (and significant) association between population density and COVID-19 morbidity in districts in Tehran. And two of the most complete studies in the US by Hamidi et al. [@Hamidi2020longitudinal; @Hamidi2020density] used an extensive set of controls to find negative and significant correlations between density at the level of counties in the US and COVID-19 cases and fatalities.

As can be seen, these studies are implemented at different scales in different regions of the world. They also use a range of techniques, from correlation analysis, to multivariate regression, spatial regressions, and machine learning techniques. This is natural and to be expected: individual researchers have only limited time and expertise. This is why reproducibility is important. To pick an example (which will be further elaborated in the following sections), the study of Sy et al. [-@Sy2021population; hereafter SWN] would immediately grab the attention of a researcher with expertise in spatial modelling. Such an expert would likely ask some of the following questions: how were missing counties treated? Is it possible to spatially interpolate missing observations? What are the implications of the spatial sampling framework used in the analysis? Was there evidence of spatial autocorrelation in the residuals of the models? These are questions that in most cases would not occur to a researcher who has not been exposed to spatial statistics or spatial econometrics. Nonetheless, they are relevant and important. Fortunately, SWN give an example of a reasonably open, reproducible research product: their paper is accompanied by (most of) the data and (most of) the code used in the analysis. This means that an independent expert can, with only a moderate investment of time and effort, replicate the results in the paper, as well as ask additional questions.

Alas, reproducibility is not necessarily the norm.

There are various reasons why a project can fail to be reproducible. In some cases, there might be legitimate reasons to withhold the data, perhaps due to confidentiality and privacy reasons [e.g., @Lee2020human]. But in many other cases the data are publicly available, as has been commonly the case with population-level COVID-19 information. Often the provenance of the data is documented, but the data themselves are not shared [e.g., @Amadu2021assessing; @Bhadra2021impact; @Cruz2020exploring; @Feng2020spread; @Fielding2020social; @Hamidi2020longitudinal; @Hamidi2020density; @Inbaraj2021seroprevalence; @Souris2020covid]. As any researcher can attest, whether a graduate student or a seasoned scientist, collecting, organizing, and preparing data for a project can take a substantial amount of time. Pointing to the sources of data, even when these sources are public, is a small step towards reproducibility-but only a very small one. Faced with the prospect of having to recreate a data set from raw sources is probably sufficient to dissuade all but the most dedicated (or stubborn) researcher. This is true even if part of the data are shared [e.g., @Wong2020spreading]. In other cases, data are shared, but the processes to document the preparation of the data are not fully documented [e.g., @Ahmad2020association; @Skorka2020macroecology]. These processes matter, as shown by the errors in the spreadsheets of Reinhart and Rogoff [@Herndon2014high], and the data of biologist Jonathan Pruitt that led to an "avalanche" of paper retractions^[\url{https://doi.org/10.1038/d41586-020-00287-y}]. Another situation is when papers share well-documented data, but fail to provide the code used in the analysis [e.g., @Noury2021how; @Pequeno2020air; @Wang2021transmission]. Making code available only "on demand" [e.g., @Brandtner2021creatures] is an unnecessary barrier when most journals offer the facility to share supplemental materials online. Then there are those papers that strive towards reproducibility, sharing well-documented processes and data, as well as the code used in any analyses reported [e.g., @Paez2020spatio; @Feyman2020effectiveness; @Stephens2021impact; @White2020state].

<!--
@Ahmad2020association -> code is not shared, data are provided but data pre-processing is not documented
@Amadu2021assessing -> code is not shared, data provenance is documented, data are not shared
@Bhadra2021impact -> (code and data not available; only data provenance is documented)
@Brandtner2021creatures -> code is available on demand, data are shared
@Cruz2020exploring -> code is shared, sources of data are documented, data are not actually provided
@Feng2020spread -> code not shared, data provenance is documented, data are not shared
@Feyman2020effectiveness -> code and data are provided
@Fielding2020social -> code is not shared, data provenance is documented, data are not actually provided
@Hamidi2020longitudinal, @Hamidi2020density ->  (code and data not available)
@Inbaraj2021seroprevalence -> code is not shared, data are not shared
@Lee2020human -> code not provided, data sources are documented but data are not shared (privacy & confidentiality)
@Noury2021how -> code is not shared, data are shared
@Pequeno2020air -> (raw data supplied in suplemental files, code not available)
@Roy2020factors -> code is not shared, data are provided and data processing is documented
@Skorka2020macroecology -> code and data are shared but data processing is not documented, 
@Souris2020covid -> code not provided, data sources are documented but data are not shared
@Stephens2021impact -> code and data are shared
@Wang2021transmission -> code is not shared, data are available
@White2020state -> code and data are in repository
@Wong2020spreading -> code not provided, data are shared but data preprocessing is not documented
-->

## Replicating SWN

Fit (mixed) linear models as in Sy et al.:
```{r incl}
table1model1 <- lme(R ~ density_log , 
                    random = ~ 1| state, 
                    data = county_geo_clean %>%
                      filter(R > 0))
summary(table1model1)
intervals(table1model1)
```

Linear mixed models of R0 and density + % private transportation
```{r}
table1model2 <- lme(R ~ density_log + private , 
                    random = ~ 1| state, 
                    data = county_geo_clean %>%
                      filter(R > 0))
summary(table1model2)
intervals(table1model2)
```

Linear mixed models of R0 and density + % private transportation + median income
```{r}
table1model3 <- lme(R ~ density_log + private + hincome, 
                    random = ~ 1| state, 
                    data = county_geo_clean %>%
                      filter(R > 0))
summary(table1model3)
intervals(table1model3)
```

Linear mixed models of R0 and density + % private transportation + median income + interaction of density and % private transportation
```{r}
table1model4 <- lme(R ~ density_log*private + hincome, 
                    random = ~ 1| state, 
                    data = county_geo_clean %>%
                      filter(R > 0))
summary(table1model4)
intervals(table1model4)
```

# Some relevant questions

Alas, despite decades' worth of developments in the field of geographical analysis, not all research presented to date has used proper methods for the study of COVID-19. While the answer to the question "do spatial effects really matter in regression analysis" was definitively answered in the positive at least 40 years ago, in practice many researchers continue to ignore the pitfalls of ignoring them. In this paper, I present a reanalysis of the data used by Sy et al. (2021) to study the correlations between the basic reproductive number of COVID-19 and population density in counties. I highlight two related issues: non-systematic sampling in space and spatial autocorrelation. The reanalysis is based on the use of tobit models to account for non-systematic sampling, and spatially autoregressive tobit models to account for spatial autocorrelation in the data generation process. The reanalysis highlights the importance of openness and reproducibility in COVID-19 research. Finally, the results provide a sobering example of the risks of not using appropriate methods in the analysis of geographical data. Furthermore, 




## Fit tobit version of models

```{r}
table1model1 <- censReg(R ~ density_log, 
                        left = 0,
                    data = county_geo_clean)
summary(table1model1)
```

Linear mixed models of R0 and density + % private transportation
```{r}
table1model2 <- censReg(R ~ density_log + private, 
                    data = county_geo_clean)
summary(table1model2)
```

Linear mixed models of R0 and density + % private transportation + median income
```{r}
table1model3 <- censReg(R ~ density_log + private + hincome, 
                    data = county_geo_clean)
summary(table1model3)
```

Tobit models of R0 and density + % private transportation + median income + interaction of density and % private transportation
```{r}
table1model4 <- censReg(R ~ density_log*private + hincome, 
                    data = county_geo_clean)
summary(table1model4)

```

## Spatially autoregressive tobit

Fit spatially autoregressive tobit:
```{r}
# Fit SAR Tobit
fit_sartobit <- sartobit(R ~ density_log + private + hincome_log,
                         B,
                         ndraw = 1000,
                         burn.in = 200, 
                         showProgress = TRUE,
                         data = county_geo_clean,
                         computeMarginalEffects = TRUE)
summary(fit_sartobit)
impacts(fit_sartobit)
```

# Conclusion

Words go here.

# References {#references .unnumbered}
